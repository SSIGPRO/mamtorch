{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c453b48c-0364-41f9-a7f9-584aaf5af1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbf6bb-c63a-4c5c-ad11-1bffcf8e7805",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import mamtorch library\n",
    "You need to have mamtorch folder in this directory and to install mamtorchkernel by launching, from mamtorch folder, \"python kernelsetup.py install\" (to improve compiling time, install ninja through \"pip install ninja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbd1d77-917f-4ece-b5d4-f57cf1d7bd9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mamtorch # Remember to install mamtorchkernel through mamtorch/kernelsetup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1899e5-978d-454a-a560-cb4813660f9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select the GPU\n",
    "Currently, MAM kernels are implemented only for usage on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ec364b-ce3d-4f2a-b40e-8bc8981c43c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select GPU\n",
    "gpu_id = 0\n",
    "# Check if the GPU is available, and if so, use it\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "# You need a gpu to use MAM kernel! (No cpu-based implementation available)\n",
    "if(device == \"cpu\"):\n",
    "    raise \"No GPU device available! MAM kernels are not available.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7e2ad-bf12-419f-a122-a85d265d799e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define a simple feedforward DNN containing a MAM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331b63f4-583b-4f30-bdd4-4380f1d92d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a simple feedforward neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Instantiate a MAC fc layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Instantiate a MAM fc layer\n",
    "        self.fc2_mam = mamtorch.MAMDense(hidden_size1, hidden_size2, bias=True, beta=True, beta_epochs=4)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Instantiate the output layer\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2_mam(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Hyperparameters\n",
    "input_size = 28 * 28  # MNIST image size\n",
    "hidden_size1 = 512\n",
    "hidden_size2 = 256\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74fe1d2-ac19-4570-b311-ab984865dac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load MNIST dataset and apply transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902c52ec-cf35-4712-a285-23257c6e4960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c1f59-a927-43cd-b13d-f709316049ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "Initialize the model, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac67d50-250c-4f8d-bffe-1e828fb94362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e2f5c-4e59-41ff-ae30-d66e1daabe62",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05729cd3-8f17-4235-acd1-4263fc555306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy on test set: 7.55%\n",
      "Epoch [1/10]\n",
      "Training step [938/938], Loss: 0.2021\n",
      "Validation accuracy on test set: 84.36%\n",
      "Elapsed time = 24.372 s\n",
      "Epoch [2/10]\n",
      "Training step [938/938], Loss: 0.4547\n",
      "Validation accuracy on test set: 86.26%\n",
      "Elapsed time = 24.087 s\n",
      "Epoch [3/10]\n",
      "Training step [938/938], Loss: 0.3886\n",
      "Validation accuracy on test set: 86.44%\n",
      "Elapsed time = 23.932 s\n",
      "Epoch [4/10]\n",
      "Training step [526/938], Loss: 0.2599\r"
     ]
    }
   ],
   "source": [
    "# Initialize the selection matrix list.\n",
    "# Here, for each training epoch, we store the number of times each interconnection has been used\n",
    "# I.E., the selection count\n",
    "selection_matrix_list = []\n",
    "\n",
    "print(\"Validation with random weights...\", end=\"\\r\")\n",
    "model.eval() # set evaluation mode\n",
    "\n",
    "# reset the selection count in the mam layer\n",
    "model.fc2_mam.reset_selection_count()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28 * 28).to(device)  # Flatten the input images\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # update the selection count with the results of this batch\n",
    "    model.fc2_mam.update_selection_count()\n",
    "    \n",
    "    # get the predicted class\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # evaluate the correct values agaist the total evaluated\n",
    "    correct += (predicted == labels.to(device)).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "# evaluate accuracy\n",
    "accuracy = correct / total\n",
    "print(f'Validation accuracy on test set: {accuracy*100:.2f}%')\n",
    "\n",
    "# add evaluated selection count matrix to the list\n",
    "# (as the sum of the count of interconnections selected as maximum and as minimum)\n",
    "selection_matrix_list += [model.fc2_mam.max_selection_count + model.fc2_mam.min_selection_count]\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.perf_counter()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "    model.train() # se training mode\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28 * 28).to(device)  # Flatten the input images\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Training step [{i + 1}/{total_step}], Loss: {loss.item():.4f}', end='\\r')\n",
    "    print()\n",
    "    \n",
    "    print(\"Validation...\", end=\"\\r\")\n",
    "    model.eval() # set evaluation mode\n",
    "    \n",
    "    # reset the selection count in the mam layer\n",
    "    model.fc2_mam.reset_selection_count()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28 * 28).to(device)  # Flatten the input images\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # update the selection count with the results of this batch\n",
    "        model.fc2_mam.update_selection_count()\n",
    "        \n",
    "        # get the predicted class\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # evaluate the correct values agaist the total evaluated\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    accuracy = correct / total\n",
    "    print(f'Validation accuracy on test set: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # add evaluated selection count matrix to the list\n",
    "    # (as the sum of the count of interconnections selected as maximum and as minimum)\n",
    "    selection_matrix_list += [model.fc2_mam.max_selection_count + model.fc2_mam.min_selection_count]\n",
    "    \n",
    "    # update the value of beta for vanishing contributes\n",
    "    model.fc2_mam.adjust_beta(epoch)\n",
    "    \n",
    "    print(f\"Elapsed time = {time.perf_counter()-start_time:.3f} s\")\n",
    "    \n",
    "print(\"Training end.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86b60e-97d7-43dc-a698-5a2619cc6927",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analysis on the interconnections\n",
    "1) How many interconnections have been selected at least once for each training epoch?\n",
    "2) How many times each interconnection has been selected as max/min for each training epoch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7ee53c-2e3b-4cae-b0e0-b39767c973b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selection_matrix_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     selected_interconnections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mselection_matrix_list\u001b[49m[i]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      6\u001b[0m     total_interconnections \u001b[38;5;241m=\u001b[39m selection_matrix_list[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mselection_matrix_list[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'selection_matrix_list' is not defined"
     ]
    }
   ],
   "source": [
    "legend_list = []\n",
    "data_list = []\n",
    "\n",
    "for i in range(num_epochs+1):\n",
    "    selected_interconnections = int(torch.sum(selection_matrix_list[i]>0))\n",
    "    total_interconnections = selection_matrix_list[i].shape[0]*selection_matrix_list[i].shape[1]\n",
    "    print(\"Training epoch\", i)\n",
    "    print(f\"Number of selected interconnections: {selected_interconnections} \"\n",
    "          f\"({selected_interconnections/total_interconnections*100:.2f}%)\")\n",
    "    data_list += [np.histogram(selection_matrix_list[i].cpu().numpy().flatten(), bins=np.max(selection_matrix_list[i].cpu().numpy()))]\n",
    "    legend_list += [f\"epoch {i}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba3765-07c3-420b-829b-fcc8914c487c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "cmap = plt.get_cmap('jet')\n",
    "for i in range(num_epochs):\n",
    "    plt.plot(data_list[i][1][:-1], data_list[i][0], linewidth=0.5, color=cmap(int(i/num_epochs*255)))\n",
    "plt.grid()\n",
    "plt.xlabel(\"Selection count\")\n",
    "plt.ylabel(\"Number of interconnections\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(legend_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9765c2-91e0-4597-a450-23122dbf6943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-01-16 17:08:02 2387956:2387956 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.12%       1.366ms       100.00%        1.096s        1.096s       0.000us         0.00%     220.000us     220.000us          16 b          16 b       8.63 Mb      -8.00 Kb             1  \n",
      "                                       MAMDenseFunction         0.03%     351.000us         0.23%       2.525ms       2.525ms     172.000us        78.18%     186.000us     186.000us           0 b           0 b       3.00 Kb    -322.00 Kb             1  \n",
      "void mamdense_forward_cuda_kernel<float>(float const...         0.00%       0.000us         0.00%       0.000us       0.000us     172.000us        78.18%     172.000us     172.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::copy_         0.01%     122.000us         0.17%       1.858ms     309.667us      18.000us         8.18%      18.000us       3.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                           aten::linear         0.01%      77.000us        99.58%        1.091s     363.801ms       0.000us         0.00%      15.000us       5.000us           0 b           0 b       8.13 Mb           0 b             3  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         5.45%      12.000us       6.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                            aten::addmm         0.62%       6.816ms        99.55%        1.091s     545.549ms      11.000us         5.00%      11.000us       5.500us           0 b           0 b       8.13 Mb       6.13 Mb             2  \n",
      "                                       aten::contiguous         0.00%       9.000us         0.01%     143.000us     143.000us       0.000us         0.00%       7.000us       7.000us           0 b           0 b     512.00 Kb           0 b             1  \n",
      "                                            aten::clone         0.00%      46.000us         0.01%     134.000us     134.000us       0.000us         0.00%       7.000us       7.000us           0 b           0 b     512.00 Kb           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         3.18%       7.000us       7.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.096s\n",
      "Self CUDA time total: 220.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-01-16 17:08:03 2387956:2387956 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2024-01-16 17:08:03 2387956:2387956 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "images = test_loader.dataset[batch_size][0].view(-1, 28 * 28).to(device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, with_stack=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        outputs = model(images)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b3bbd-eda4-4159-86f5-e3918b4fd8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
